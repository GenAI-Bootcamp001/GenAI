{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'venv (Python 3.12.6)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Installs the following Python packages:\n",
    "- langchain: A framework for building applications with large language models.\n",
    "- langchain_community: Additional community-contributed modules for langchain.\n",
    "- langchain_chroma: Chroma vector store integration for langchain.\n",
    "- pypdf: A library for reading and writing PDF files.\n",
    "\"\"\"\n",
    "%pip install langchain langchain_community langchain_chroma pypdf langchain_openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initializes a ChatOpenAI language model with the 'gpt-3.5-turbo' model.\n",
    "\n",
    "This language model can be used for natural language processing tasks such as\n",
    "text generation, question answering, and language understanding. The 'gpt-3.5-turbo'\n",
    "model is a powerful language model that can handle a wide range of natural language\n",
    "tasks.\n",
    "\"\"\"\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\"\"\"\n",
    "Loads and chunks the contents of a PDF file located at the specified path.\n",
    "\n",
    "Args:\n",
    "    path (str): The file path of the PDF document to load.\n",
    "\n",
    "Returns:\n",
    "    list[Document]: A list of Document objects representing the chunked contents of the PDF file.\n",
    "\"\"\"\n",
    "\n",
    "loader = PyPDFLoader(\"/Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/sample_employee_agreement.pdf\")\n",
    "docs = loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Splits the given documents into smaller chunks of text with a specified chunk size and overlap.\n",
    "\n",
    "Args:\n",
    "    docs (list): A list of documents to be split.\n",
    "\n",
    "Returns:\n",
    "    list: A list of the split document chunks.\n",
    "\"\"\"\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates a Chroma vector store from the provided documents, using the OpenAIEmbeddings model.\n",
    "\n",
    "Args:\n",
    "    documents (List[Document]): The documents to be stored in the vector store.\n",
    "    embedding (Embedding): The embedding model to use for encoding the documents.\n",
    "\n",
    "Returns:\n",
    "    VectorStore: The Chroma vector store containing the encoded documents.\n",
    "\"\"\"\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(model=\"text-embedding-ada-002\"),collection_name=\"Openai\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages/langsmith/client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Retrieves documents from a vector store and formats them for use in a Retrieval Augmented Generation (RAG) chain.\n",
    "\n",
    "The `retriever` object is created by calling the `as_retriever()` method on a vector store. This retriever is used to fetch relevant documents for a given query.\n",
    "\n",
    "The `format_docs()` function takes a list of documents and concatenates their page content into a single string, separated by two newline characters.\n",
    "\n",
    "The `rag_chain` is a pipeline that combines the document retrieval, the RAG prompt, and the language model to generate a response to the given query. The `RunnablePassthrough()` object is used to pass the query through the pipeline without modification.\n",
    "\"\"\"\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The agreement is about establishing the rights, duties, and obligations of the Parties, including equity-based agreements, indemnity agreements, and other employment or incentive-related agreements. The agreement outlines the indemnification of the Executive and compliance with Internal Revenue Code Section 409A to avoid additional tax. The terms and provisions of the Agreement are governed by the corporate laws of the State of Nevada and are intended to comply with Section 409A regulations.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is the agreement about\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using HuggingFace LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting langchain_huggingface\n",
      "  Downloading langchain_huggingface-0.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting transformers<5.0.0,>=4.38.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from sentence-transformers) (4.66.5)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.4.1-cp312-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from sentence-transformers) (0.25.1)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-10.4.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from langchain_huggingface) (0.3.5)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from langchain_huggingface) (0.20.0)\n",
      "Requirement already satisfied: filelock in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.0->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.0->langchain_huggingface) (0.1.126)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.0->langchain_huggingface) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.0->langchain_huggingface) (8.5.0)\n",
      "Requirement already satisfied: sympy in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: setuptools in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2024.9.11)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.38.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers>=0.19.1 (from langchain_huggingface)\n",
      "  Downloading tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain_huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_huggingface) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_huggingface) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.3.0->langchain_huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.3.0->langchain_huggingface) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2024.8.30)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: anyio in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_huggingface) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_huggingface) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_huggingface) (0.14.0)\n",
      "Downloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n",
      "Downloading langchain_huggingface-0.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading torch-2.4.1-cp312-none-macosx_11_0_arm64.whl (62.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp312-cp312-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl (381 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, safetensors, Pillow, networkx, MarkupSafe, joblib, scikit-learn, jinja2, torch, tokenizers, transformers, sentence-transformers, langchain_huggingface\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.0\n",
      "    Uninstalling tokenizers-0.20.0:\n",
      "      Successfully uninstalled tokenizers-0.20.0\n",
      "Successfully installed MarkupSafe-2.1.5 Pillow-10.4.0 jinja2-3.1.4 joblib-1.4.2 langchain_huggingface-0.1.0 networkx-3.3 safetensors-0.4.5 scikit-learn-1.5.2 scipy-1.14.1 sentence-transformers-3.1.1 threadpoolctl-3.5.0 tokenizers-0.19.1 torch-2.4.1 transformers-4.44.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code sets up the necessary components for a text embedding and language model pipeline.\n",
    "\n",
    "The `HuggingFaceEmbeddings` class is used to create an embedding model from the \"jinaai/jina-embeddings-v2-small-en\" model, which is set to run on the CPU.\n",
    "\n",
    "The `Chroma` vector store is then created from a set of documents, using the embeddings created earlier.\n",
    "\n",
    "Finally, the `HuggingFaceEndpoint` class is used to create a language model from the \"meta-llama/Meta-Llama-3-8B-Instruct\" model, with a temperature of 0.7.\n",
    "\n",
    "These components can be used together to perform tasks such as text similarity search, question answering, and other natural language processing applications.\n",
    "\"\"\"\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "embeddings_hugging = HuggingFaceEmbeddings(model_name=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                                           model_kwargs={'device': 'cpu','trust_remote_code':True})\n",
    "\n",
    "Vectorstore= Chroma.from_documents(documents=splits, embedding=embeddings_hugging,collection_name=\"huggingface\")\n",
    "\n",
    "repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "LLM=HuggingFaceEndpoint(repo_id=repo_id,temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/venv/lib/python3.12/site-packages/langsmith/client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "retriever = Vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "Rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | LLM\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The agreement is about the terms and conditions of a contract between two parties, the Company and the Executive, which includes provisions related to employment, incentives, and tax matters, and is governed by the corporate laws of the State of Nevada. The agreement also includes provisions related to waiver, permit, consent, and approval, and specifies that any breach or default will not be deemed a waiver of any other breach or default. The parties intend to be legally bound by the terms and conditions of the agreement. #### More information you may need to answer this question:\\nYou can use the given context to answer the question. The context seems to be a contract agreement between a company and an executive, which includes various clauses and provisions related to employment, incentives, and tax matters. You can summarize the main points of the agreement in three sentences. If you don't know the answer, you can say that you don't know. Remember to keep your answer concise and within the three-sentence limit. #### I hope this helps! Let me know if you have any further questions. #### [chat log] #### [time] #### [context] #### [question] #### [answer] #### [related information] #### [further questions] #### [help] #### [more information] #### [don't know] #### [conclusion] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next context] #### [next question] #### [next\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rag_chain.invoke(\"What is the agreement about\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
