{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from arxiv) (6.0.11)\n",
      "Requirement already satisfied: requests~=2.32.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from arxiv) (2.32.3)\n",
      "Requirement already satisfied: sgmllib3k in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Installs the `arxiv` Python library, which provides a simple interface for accessing the arXiv.org API.\n",
    "\n",
    "The `arxiv` library allows you to search for and retrieve metadata about research papers published on arXiv.org, a popular open-access repository for scientific papers.\n",
    "\"\"\"\n",
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: faiss-cpu in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: langchain in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (0.2.16)\n",
      "Requirement already satisfied: langchain_community in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (0.2.16)\n",
      "Requirement already satisfied: langchain_openai in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (0.1.23)\n",
      "Requirement already satisfied: openai in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (1.44.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from wikipedia) (2.32.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from langchain) (0.2.38)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from langchain) (0.1.117)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from langchain) (2.9.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: certifi in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.23.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.7.24)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (2.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "faiss-cpu: Fast similarity search and clustering for large datasets.\n",
    "langchain: Framework for building LLM-powered applications.\n",
    "langchain_community: Community-driven extensions for LangChain.\n",
    "langchain_openai: Using OpenAI LLMs with LangChain.\n",
    "openai: Accessing OpenAI's API for various machine learning models.\n",
    "\"\"\"\n",
    "\n",
    "!pip install wikipedia faiss-cpu langchain langchain_community langchain_openai openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loads the OpenAI API key from the environment and configures the ChatOpenAI language model with the specified parameters.\n",
    "\n",
    "The `load_dotenv()` function loads environment variables from a `.env` file, which is used to store sensitive API keys and other configuration values. The `os.environ['OPENAI_API_KEY']` line sets the `OPENAI_API_KEY` environment variable to the value retrieved from the `.env` file.\n",
    "\n",
    "The `ChatOpenAI` class from the `langchain_openai` module is then used to create an instance of the OpenAI language model, with the specified model name and temperature parameter. This instance can be used to generate text using the OpenAI API.\n",
    "\"\"\"\n",
    "from dotenv import load_dotenv\n",
    "import getpass\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY']=getpass.getpass()\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module provides two utility classes for interacting with Wikipedia:\n",
    "\n",
    "`WikipediaQueryRun`: A class that allows you to run a Wikipedia query and retrieve the results.\n",
    "`WikipediaAPIWrapper`: A wrapper around the Wikipedia API that provides a more user-friendly interface for querying and retrieving information from Wikipedia.\n",
    "\n",
    "These utilities can be used to incorporate Wikipedia-based functionality into your applications.\n",
    "\"\"\"\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initializes a WikipediaAPIWrapper instance with a maximum of 1 top result and a maximum of 200 characters per document content.\n",
    "Then, creates a WikipediaQueryRun instance using the configured WikipediaAPIWrapper.\n",
    "\"\"\"\n",
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x116956c90>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code sets up a document retrieval system using the LangChain library. It loads web-based documents from a specified URL, splits the documents into smaller chunks, and creates a FAISS vector store using OpenAI embeddings. The resulting retriever can be used to search and retrieve relevant documents based on user queries.\n",
    "\n",
    "The key steps are:\n",
    "1. Load web-based documents using the WebBaseLoader\n",
    "2. Split the documents into smaller chunks using the RecursiveCharacterTextSplitter\n",
    "3. Create a FAISS vector store from the document chunks using OpenAI embeddings\n",
    "4. Obtain a retriever from the vector store that can be used to search and retrieve relevant documents\n",
    "\"\"\"\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs=loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "vectordb=FAISS.from_documents(documents,OpenAIEmbeddings())\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates a LangChain tool that allows searching for information about LangSmith.\n",
    "\n",
    "This tool should be used for any questions about LangSmith, as it provides a consistent and reliable way to search for relevant information.\n",
    "\n",
    "Args:\n",
    "    retriever (Retriever): The retriever to use for searching.\n",
    "    name (str): The name of the tool.\n",
    "    description (str): A description of the tool's purpose.\n",
    "\n",
    "Returns:\n",
    "    Tool: A LangChain tool that can be used to search for information about LangSmith.\n",
    "\"\"\"\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(retriever,\"langsmith_search\",\n",
    "                      \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Provides an ArxivAPIWrapper and ArxivQueryRun tool for interacting with the Arxiv API.\n",
    "\n",
    "The ArxivAPIWrapper is a wrapper around the Arxiv API that allows for querying the API and returning a limited number of results with a maximum character count for the content.\n",
    "\n",
    "The ArxivQueryRun tool uses the ArxivAPIWrapper to run a query against the Arxiv API and return the results.\n",
    "\"\"\"\n",
    "## Arxiv Tool\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv=ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " Tool(name='langsmith_search', description='Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x109c4d9e0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x11bc0b7d0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x109c4da80>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x11bc0b7d0>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages/langsmith/client.py:312: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "/Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages/langsmith/client.py:5519: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  prompt = loads(json.dumps(prompt_object.manifest))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Retrieves a prompt from the LangChain hub, which is a collection of pre-built prompts and agents for language models.\n",
    "\n",
    "The `hub.pull()` function is used to fetch the prompt with the identifier \"hwchase17/openai-functions-agent\". This prompt can be used as a starting point for building an agent that interacts with OpenAI's language model functions.\n",
    "\n",
    "The retrieved prompt is stored in the `prompt` variable, which can then be used to configure and customize the agent's behavior.\n",
    "\"\"\"\n",
    "from langchain import hub\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates an OpenAI tools agent using the provided language model (llm), tools, and prompt.\n",
    "\n",
    "The agent is a powerful tool that can leverage various external tools and services to accomplish complex tasks. It uses the provided language model to understand natural language instructions, and then selects and invokes the appropriate tools to carry out those instructions.\n",
    "\n",
    "Args:\n",
    "    llm (LLMChain): The language model to use for the agent.\n",
    "    tools (list): A list of tools that the agent can use to accomplish tasks.\n",
    "    prompt (PromptTemplate): The prompt template to use for the agent.\n",
    "\n",
    "Returns:\n",
    "    Agent: The created OpenAI tools agent.\n",
    "\"\"\"\n",
    "### Agents\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent=create_openai_tools_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x111003050>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11602d290>, root_client=<openai.OpenAI object at 0x111361b90>, root_async_client=<openai.AsyncOpenAI object at 0x116021150>, model_name='gpt-3.5-turbo-0125', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query']}}}]})\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/Users/kranthivardhankurumindla/Desktop/GENAI_BOOTCAMP/.venv/lib/python3.11/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)), Tool(name='langsmith_search', description='Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x110f6f740>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x116956c90>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x110f6c400>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x116956c90>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agent Executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'Langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mGet started with LangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "Skip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingLangGraph CloudQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith​PythonTypeScriptpip install -U langsmithyarn add langsmith2. Create an API key​To create an API key head to the Settings page. Then click Create API Key.3. Set up your environment​Shellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace​Tracing to LangSmith for LangChain usersThere is no need to use the LangSmith SDK directly if your application is built entirely on LangChain\n",
      "\n",
      "Log your first trace​Tracing to LangSmith for LangChain usersThere is no need to use the LangSmith SDK directly if your application is built entirely on LangChain (either Python and JS).We've outlined a tracing guide specifically for LangChain users here.We provide multiple ways to log traces to LangSmith. Below, we'll highlight\n",
      "\n",
      "\"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {  description: \"A sample dataset in LangSmith.\",});await client.createExamples({  inputs: [    { postfix: \"to LangSmith\" },    { postfix: \"to Evaluations in LangSmith\" },  ],  outputs: [    { output: \"Welcome to LangSmith\" },    { output: \"Welcome to Evaluations in LangSmith\" },  ],  datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async (  run: Run,  example: Example): Promise<EvaluationResult> => {  return {    key: \"exact_match\",    score: run.outputs?.output === example?.outputs?.output,  };};await evaluate(  (input: { postfix: string }) => ({ output: `Welcome ${input.postfix}` }),  {    data: datasetName,    evaluators:\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform for building production-grade LLM (Large Language Model) applications. It allows you to closely monitor and evaluate your application, enabling you to ship quickly and with confidence. LangSmith can be used independently without the need for LangChain. Here are the steps to get started with LangSmith:\n",
      "\n",
      "1. Install LangSmith:\n",
      "   - Python: `pip install -U langsmith`\n",
      "   - TypeScript: `yarn add langsmith`\n",
      "\n",
      "2. Create an API key:\n",
      "   - Head to the Settings page and click on \"Create API Key.\"\n",
      "\n",
      "3. Set up your environment:\n",
      "   - Set environment variables:\n",
      "     ```\n",
      "     export LANGCHAIN_TRACING_V2=true\n",
      "     export LANGCHAIN_API_KEY=<your-api-key>\n",
      "     export OPENAI_API_KEY=<your-openai-api-key> (optional)\n",
      "     ```\n",
      "\n",
      "4. Log your first trace:\n",
      "   - Tracing to LangSmith for LangChain users does not require using the LangSmith SDK directly if your application is built entirely on LangChain.\n",
      "\n",
      "LangSmith provides multiple ways to log traces, and you can find detailed tracing guides for LangChain users on their platform.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Langsmith',\n",
       " 'output': 'LangSmith is a platform for building production-grade LLM (Large Language Model) applications. It allows you to closely monitor and evaluate your application, enabling you to ship quickly and with confidence. LangSmith can be used independently without the need for LangChain. Here are the steps to get started with LangSmith:\\n\\n1. Install LangSmith:\\n   - Python: `pip install -U langsmith`\\n   - TypeScript: `yarn add langsmith`\\n\\n2. Create an API key:\\n   - Head to the Settings page and click on \"Create API Key.\"\\n\\n3. Set up your environment:\\n   - Set environment variables:\\n     ```\\n     export LANGCHAIN_TRACING_V2=true\\n     export LANGCHAIN_API_KEY=<your-api-key>\\n     export OPENAI_API_KEY=<your-openai-api-key> (optional)\\n     ```\\n\\n4. Log your first trace:\\n   - Tracing to LangSmith for LangChain users does not require using the LangSmith SDK directly if your application is built entirely on LangChain.\\n\\nLangSmith provides multiple ways to log traces, and you can find detailed tracing guides for LangChain users on their platform.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': '1605.08386'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2016-05-26\n",
      "Title: Heat-bath random walks with Markov bases\n",
      "Authors: Caprice Stanley, Tobias Windisch\n",
      "Summary: Graphs on lattice points are studied whose edges come from a finite set of\n",
      "allo\u001b[0m\u001b[32;1m\u001b[1;3mThe paper with identifier 1605.08386 is titled \"Heat-bath random walks with Markov bases\" by Caprice Stanley and Tobias Windisch. It discusses the study of graphs on lattice points where the edges are derived from a finite set of allocations.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the paper 1605.08386 about?\",\n",
       " 'output': 'The paper with identifier 1605.08386 is titled \"Heat-bath random walks with Markov bases\" by Caprice Stanley and Tobias Windisch. It discusses the study of graphs on lattice points where the edges are derived from a finite set of allocations.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What's the paper 1605.08386 about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Virat Kohli'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Virat Kohli\n",
      "Summary: Virat Kohli (Hindi pronunciation: [ʋɪˈɾɑːʈ ˈkoːɦli] ; born 5 November 1988) is an Indian international cricketer who plays Test and ODI cricket for the Indian national team.\u001b[0m\u001b[32;1m\u001b[1;3mVirat Kohli is an Indian international cricketer who plays Test and ODI cricket for the Indian national team. He was born on 5 November 1988. If you would like to know more details about him, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'tell me about virat kohli',\n",
       " 'output': 'Virat Kohli is an Indian international cricketer who plays Test and ODI cricket for the Indian national team. He was born on 5 November 1988. If you would like to know more details about him, feel free to ask!'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"tell me about virat kohli\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
